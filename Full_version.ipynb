{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "#sc = SparkContext()\n",
    "#spark = SparkSession.builder.appName(\"HW4-1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (SparkConf()\n",
    "    .set(\"spark.driver.maxResultSize\", \"2g\"))\n",
    "\n",
    "# Create new context\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"HW4-1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://502-mountain-dew-spotify/training_set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://502-mountain-dew-spotify/track_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- session_position: string (nullable = true)\n",
      " |-- session_length: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: string (nullable = true)\n",
      " |-- skip_2: string (nullable = true)\n",
      " |-- skip_3: string (nullable = true)\n",
      " |-- not_skipped: string (nullable = true)\n",
      " |-- context_switch: string (nullable = true)\n",
      " |-- no_pause_before_play: string (nullable = true)\n",
      " |-- short_pause_before_play: string (nullable = true)\n",
      " |-- long_pause_before_play: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekfwd: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: string (nullable = true)\n",
      " |-- hist_user_behavior_is_shuffle: string (nullable = true)\n",
      " |-- hour_of_day: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- premium: string (nullable = true)\n",
      " |-- context_type: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_start: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_end: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- us_popularity_estimate: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- beat_strength: string (nullable = true)\n",
      " |-- bounciness: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- dyn_range_mean: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- flatness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mechanism: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- organism: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- tempo: string (nullable = true)\n",
      " |-- time_signature: string (nullable = true)\n",
      " |-- valence: string (nullable = true)\n",
      " |-- acoustic_vector_0: string (nullable = true)\n",
      " |-- acoustic_vector_1: string (nullable = true)\n",
      " |-- acoustic_vector_2: string (nullable = true)\n",
      " |-- acoustic_vector_3: string (nullable = true)\n",
      " |-- acoustic_vector_4: string (nullable = true)\n",
      " |-- acoustic_vector_5: string (nullable = true)\n",
      " |-- acoustic_vector_6: string (nullable = true)\n",
      " |-- acoustic_vector_7: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spotify.join(feature, spotify.track_id_clean == feature.track_id , \"inner\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2072002577"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2072002577"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[session_id: string, session_position: string, session_length: string, track_id_clean: string, skip_1: string, skip_2: string, skip_3: string, not_skipped: string, context_switch: string, no_pause_before_play: string, short_pause_before_play: string, long_pause_before_play: string, hist_user_behavior_n_seekfwd: string, hist_user_behavior_n_seekback: string, hist_user_behavior_is_shuffle: string, hour_of_day: string, date: string, premium: string, context_type: string, hist_user_behavior_reason_start: string, hist_user_behavior_reason_end: string, track_id: string, duration: string, release_year: string, us_popularity_estimate: string, acousticness: string, beat_strength: string, bounciness: string, danceability: string, dyn_range_mean: string, energy: string, flatness: string, instrumentalness: string, key: string, liveness: string, loudness: string, mechanism: string, mode: string, organism: string, speechiness: string, tempo: string, time_signature: string, valence: string, acoustic_vector_0: string, acoustic_vector_1: string, acoustic_vector_2: string, acoustic_vector_3: string, acoustic_vector_4: string, acoustic_vector_5: string, acoustic_vector_6: string, acoustic_vector_7: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- session_position: string (nullable = true)\n",
      " |-- session_length: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: string (nullable = true)\n",
      " |-- skip_2: string (nullable = true)\n",
      " |-- skip_3: string (nullable = true)\n",
      " |-- not_skipped: string (nullable = true)\n",
      " |-- context_switch: string (nullable = true)\n",
      " |-- no_pause_before_play: string (nullable = true)\n",
      " |-- short_pause_before_play: string (nullable = true)\n",
      " |-- long_pause_before_play: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekfwd: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: string (nullable = true)\n",
      " |-- hist_user_behavior_is_shuffle: string (nullable = true)\n",
      " |-- hour_of_day: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- premium: string (nullable = true)\n",
      " |-- context_type: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_start: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_end: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spotify.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "|          session_id|      track_id_clean|skip_1|skip_2|skip_3|not_skipped|context_switch|no_pause_before_play|short_pause_before_play|long_pause_before_play|hist_user_behavior_n_seekback|premium|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...| false| false| false|       true|             0|                   0|                      0|                     0|                            0|   true|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"hist_user_behavior_reason_start\", \"hist_user_behavior_reason_end\", \"context_type\", \"date\"\n",
    "                  ,\"hour_of_day\", \"hist_user_behavior_is_shuffle\", \"hist_user_behavior_n_seekfwd\", \"session_length\",\"session_position\"]\n",
    "df_drop = spotify.drop(*columns_to_drop)\n",
    "df_drop.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: boolean (nullable = true)\n",
      " |-- skip_2: boolean (nullable = true)\n",
      " |-- skip_3: boolean (nullable = true)\n",
      " |-- not_skipped: boolean (nullable = true)\n",
      " |-- context_switch: boolean (nullable = true)\n",
      " |-- no_pause_before_play: boolean (nullable = true)\n",
      " |-- short_pause_before_play: boolean (nullable = true)\n",
      " |-- long_pause_before_play: boolean (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: integer (nullable = true)\n",
      " |-- premium: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "for c in [\"skip_1\", \"skip_2\", \"skip_3\", \"not_skipped\", \"context_switch\", \"no_pause_before_play\",\n",
    "         \"short_pause_before_play\", \"long_pause_before_play\", \"premium\"]:\n",
    "    df_drop = df_drop.withColumn(c, df_drop[c].cast(BooleanType()))\n",
    "for c in [\"hist_user_behavior_n_seekback\"]:\n",
    "    df_drop = df_drop.withColumn(c, df_drop[c].cast(IntegerType()))  \n",
    "    \n",
    "df_drop.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "|          session_id|      track_id_clean|skip_1|skip_2|skip_3|not_skipped|context_switch|no_pause_before_play|short_pause_before_play|long_pause_before_play|hist_user_behavior_n_seekback|premium|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...| false| false| false|       true|         false|               false|                  false|                 false|                            0|   true|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+------+-----------+--------------+-----------------------------+-------+---------+\n",
      "|          session_id|      track_id_clean|skip_1|skip_2|skip_3|not_skipped|context_switch|hist_user_behavior_n_seekback|premium|Not_Pause|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+-----------------------------+-------+---------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...| false| false| false|       true|         false|                            0|   true|        1|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+-----------------------------+-------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: boolean (nullable = true)\n",
      " |-- skip_2: boolean (nullable = true)\n",
      " |-- skip_3: boolean (nullable = true)\n",
      " |-- not_skipped: boolean (nullable = true)\n",
      " |-- context_switch: boolean (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: integer (nullable = true)\n",
      " |-- premium: boolean (nullable = true)\n",
      " |-- Not_Pause: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def pause_udf(short_pause, long_pause):\n",
    "    if short_pause or long_pause:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "pause = spark.udf.register(\"pause\", pause_udf)\n",
    "\n",
    "df1 = df_drop.select(\"session_id\", \"track_id_clean\", \"skip_1\", \"skip_2\", \"skip_3\",\n",
    "                     \"not_skipped\", \"context_switch\", \"hist_user_behavior_n_seekback\",\n",
    "                     \"premium\", pause(col(\"short_pause_before_play\"), col(\"long_pause_before_play\")).alias(\"Not_Pause\"))\n",
    "df1.show(1)\n",
    "\n",
    "#df_drop1 = df_drop.join(df1, [\"session_id\"] , \"left\")\n",
    "df1 = df1.withColumn(\"Not_Pause\", df1[\"Not_Pause\"].cast(IntegerType()))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+-----------------------------+-----------+\n",
      "|          session_id|context_switch|      track_id_clean|hist_user_behavior_n_seekback|Skip_Rating|\n",
      "+--------------------+--------------+--------------------+-----------------------------+-----------+\n",
      "|0_00006f66-33e5-4...|         false|t_0479f24c-27d2-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_9099cd7b-c238-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_fc5df5ba-5396-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_23cff8d6-d874-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_64f3743c-f624-4...|                            0|          6|\n",
      "+--------------------+--------------+--------------------+-----------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def skip_rating_udf(premium, skip_1, skip_2, skip_3, not_skip, nopause):\n",
    "    if premium:\n",
    "        if skip_1:\n",
    "            skip1 = 1 - (1 - nopause)\n",
    "        else:\n",
    "            skip1 = 0\n",
    "        if skip_2:\n",
    "            skip2 = 3\n",
    "        else:\n",
    "            skip2 = 0\n",
    "        if skip_3:\n",
    "            skip3 = 5\n",
    "        else:\n",
    "            skip3 = 0\n",
    "        if not_skip:\n",
    "            notskip = 6 + (2 - 2 * nopause)\n",
    "        else:\n",
    "            notskip = 0\n",
    "        return max(skip1, skip2, skip3, notskip)\n",
    "    else:\n",
    "        if skip_1:\n",
    "            skip1 = 0\n",
    "        else:\n",
    "            skip1 = 0\n",
    "        if skip_2:\n",
    "            skip2 = 1\n",
    "        else:\n",
    "            skip2 = 0\n",
    "        if skip_3:\n",
    "            skip3 = 2\n",
    "        else:\n",
    "            skip3 = 0\n",
    "        if not_skip:\n",
    "            notskip = 5 + (1 - 1 * nopause)\n",
    "        else:\n",
    "            notskip = 0\n",
    "        return max(skip1, skip2, skip3, notskip)\n",
    "    \n",
    "skip_rating = spark.udf.register(\"skip_rating\", skip_rating_udf)\n",
    "\n",
    "df2 = df1.select(\"session_id\",\"context_switch\",\"track_id_clean\",\n",
    "                 \"hist_user_behavior_n_seekback\",skip_rating(col(\"premium\"), col(\"skip_1\"), \n",
    "                                                             col(\"skip_2\"), col(\"skip_3\"), col(\"not_skipped\"), \n",
    "                                                             col(\"Not_Pause\")).alias(\"Skip_Rating\"))\n",
    "df2.show(5)\n",
    "\n",
    "#df_drop2 = df_drop1.join(df2, [\"session_id\"] , \"left\")\n",
    "df2 = df2.withColumn(\"Skip_Rating\", df2[\"Skip_Rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|          session_id|      track_id_clean|Final_Rating|\n",
      "+--------------------+--------------------+------------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_9099cd7b-c238-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_fc5df5ba-5396-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_23cff8d6-d874-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_64f3743c-f624-4...|         6.0|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def final_rating_udf(Skip_Rating, context_switch, seekback):\n",
    "    if context_switch:\n",
    "        context = 1\n",
    "    else:\n",
    "        context = 0\n",
    "    inside = 1 - (Skip_Rating + 2*context)/10\n",
    "    seekback = seekback + 1\n",
    "    return (1 - pow(inside, (pow(seekback, 1/3)))) * 10\n",
    "\n",
    "final_rating = spark.udf.register(\"final_rating\", final_rating_udf)\n",
    "\n",
    "df3 = df2.select(\"session_id\", \"track_id_clean\",\n",
    "                 final_rating(col(\"Skip_Rating\"), col(\"context_switch\"),\n",
    "                              col(\"hist_user_behavior_n_seekback\")).alias(\"Final_Rating\"))\n",
    "df3.show(5)\n",
    "\n",
    "#df_drop3 = df_drop2.join(df3, [\"session_id\"] , \"left\")\n",
    "df3 = df3.withColumn(\"Final_Rating\", df3[\"Final_Rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|          session_id|      track_id_clean|Final_Rating_Adjust|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_9099cd7b-c238-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_fc5df5ba-5396-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_23cff8d6-d874-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_64f3743c-f624-4...|                  7|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def adjust_udf(final):\n",
    "    return final + 1\n",
    "\n",
    "adjust = spark.udf.register(\"adjust\", adjust_udf)\n",
    "\n",
    "df4 = df3.select(\"session_id\", \"track_id_clean\",\n",
    "                 adjust(col(\"Final_Rating\")).alias(\"Final_Rating_Adjust\"))\n",
    "df4.show(5)\n",
    "\n",
    "#df_drop3 = df_drop2.join(df3, [\"session_id\"] , \"left\")\n",
    "df4 = df4.withColumn(\"Final_Rating_Adjust\", df4[\"Final_Rating_Adjust\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.write.format(\"csv\").option(\"header\",\"true\").mode(\"Overwrite\").save(\"s3://olihw4/spotify_full_version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|Final_Rating_Adjust|\n",
      "+-------+-------------------+\n",
      "|  count|         2072002577|\n",
      "|   mean|  5.916154485072342|\n",
      "| stddev| 1.7028280992338234|\n",
      "|    min|                  1|\n",
      "|    max|                 11|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.describe(\"Final_Rating_Adjust\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|Final_Rating_Adjust|count(session_id)|\n",
      "+-------------------+-----------------+\n",
      "|                  1|         32930593|\n",
      "|                  6|       1153802824|\n",
      "|                  3|          8332379|\n",
      "|                  5|          7127384|\n",
      "|                  9|         87913811|\n",
      "|                  4|           159804|\n",
      "|                  8|         46665799|\n",
      "|                  7|        510759745|\n",
      "|                 10|          1727159|\n",
      "|                 11|          4328875|\n",
      "|                  2|        218254204|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df4.groupBy(\"Final_Rating_Adjust\").agg(count('session_id')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:46109)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:46109)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-99b4f99e4ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"session_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"track_id_clean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-99b4f99e4ae2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"session_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"track_id_clean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/feature.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputCol, outputCol, handleInvalid, stringOrderType)\u001b[0m\n\u001b[1;32m   2447\u001b[0m         \"\"\"\n\u001b[1;32m   2448\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIndexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2449\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"org.apache.spark.ml.feature.StringIndexer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2450\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[1;32m   1650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    981\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:46109)"
     ]
    }
   ],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df4) for column in [\"session_id\", \"track_id_clean\"] ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_index = pipeline.fit(df4).transform(df4)\n",
    "\n",
    "df_index.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-dd80c984e34f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_index' is not defined"
     ]
    }
   ],
   "source": [
    "training, test = df_index.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"session_id_index\", itemCol=\"track_id_clean_index\", ratingCol=\"Final_Rating_Adjust\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model, \"s3://olihw4//spotify_full_version_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 10.181823908017078\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Final_Rating_Adjust\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs.select(\"recommendations\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id_index: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- track_id_clean_index: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRecs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
