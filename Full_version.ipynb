{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "sc = SparkContext()\n",
    "spark = SparkSession.builder.appName(\"HW4-1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=yarn) created by __init__ at <ipython-input-1-f792f2aea63f>:7 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-957e76263643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create new context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    338\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 340\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=yarn) created by __init__ at <ipython-input-1-f792f2aea63f>:7 "
     ]
    }
   ],
   "source": [
    "#conf = (SparkConf()\n",
    "#    .set(\"spark.driver.maxResultSize\", \"2g\"))\n",
    "\n",
    "# Create new context\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"HW4-1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://502-mountain-dew-spotify/training_set/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"s3://502-mountain-dew-spotify/track_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- session_position: string (nullable = true)\n",
      " |-- session_length: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: string (nullable = true)\n",
      " |-- skip_2: string (nullable = true)\n",
      " |-- skip_3: string (nullable = true)\n",
      " |-- not_skipped: string (nullable = true)\n",
      " |-- context_switch: string (nullable = true)\n",
      " |-- no_pause_before_play: string (nullable = true)\n",
      " |-- short_pause_before_play: string (nullable = true)\n",
      " |-- long_pause_before_play: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekfwd: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: string (nullable = true)\n",
      " |-- hist_user_behavior_is_shuffle: string (nullable = true)\n",
      " |-- hour_of_day: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- premium: string (nullable = true)\n",
      " |-- context_type: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_start: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_end: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- us_popularity_estimate: string (nullable = true)\n",
      " |-- acousticness: string (nullable = true)\n",
      " |-- beat_strength: string (nullable = true)\n",
      " |-- bounciness: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      " |-- dyn_range_mean: string (nullable = true)\n",
      " |-- energy: string (nullable = true)\n",
      " |-- flatness: string (nullable = true)\n",
      " |-- instrumentalness: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- liveness: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- mechanism: string (nullable = true)\n",
      " |-- mode: string (nullable = true)\n",
      " |-- organism: string (nullable = true)\n",
      " |-- speechiness: string (nullable = true)\n",
      " |-- tempo: string (nullable = true)\n",
      " |-- time_signature: string (nullable = true)\n",
      " |-- valence: string (nullable = true)\n",
      " |-- acoustic_vector_0: string (nullable = true)\n",
      " |-- acoustic_vector_1: string (nullable = true)\n",
      " |-- acoustic_vector_2: string (nullable = true)\n",
      " |-- acoustic_vector_3: string (nullable = true)\n",
      " |-- acoustic_vector_4: string (nullable = true)\n",
      " |-- acoustic_vector_5: string (nullable = true)\n",
      " |-- acoustic_vector_6: string (nullable = true)\n",
      " |-- acoustic_vector_7: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spotify.join(feature, spotify.track_id_clean == feature.track_id , \"inner\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2072002577"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2072002577"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[session_id: string, session_position: string, session_length: string, track_id_clean: string, skip_1: string, skip_2: string, skip_3: string, not_skipped: string, context_switch: string, no_pause_before_play: string, short_pause_before_play: string, long_pause_before_play: string, hist_user_behavior_n_seekfwd: string, hist_user_behavior_n_seekback: string, hist_user_behavior_is_shuffle: string, hour_of_day: string, date: string, premium: string, context_type: string, hist_user_behavior_reason_start: string, hist_user_behavior_reason_end: string, track_id: string, duration: string, release_year: string, us_popularity_estimate: string, acousticness: string, beat_strength: string, bounciness: string, danceability: string, dyn_range_mean: string, energy: string, flatness: string, instrumentalness: string, key: string, liveness: string, loudness: string, mechanism: string, mode: string, organism: string, speechiness: string, tempo: string, time_signature: string, valence: string, acoustic_vector_0: string, acoustic_vector_1: string, acoustic_vector_2: string, acoustic_vector_3: string, acoustic_vector_4: string, acoustic_vector_5: string, acoustic_vector_6: string, acoustic_vector_7: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[session_id: string, session_position: string, session_length: string, track_id_clean: string, skip_1: string, skip_2: string, skip_3: string, not_skipped: string, context_switch: string, no_pause_before_play: string, short_pause_before_play: string, long_pause_before_play: string, hist_user_behavior_n_seekfwd: string, hist_user_behavior_n_seekback: string, hist_user_behavior_is_shuffle: string, hour_of_day: string, date: string, premium: string, context_type: string, hist_user_behavior_reason_start: string, hist_user_behavior_reason_end: string, track_id: string, duration: string, release_year: string, us_popularity_estimate: string, acousticness: string, beat_strength: string, bounciness: string, danceability: string, dyn_range_mean: string, energy: string, flatness: string, instrumentalness: string, key: string, liveness: string, loudness: string, mechanism: string, mode: string, organism: string, speechiness: string, tempo: string, time_signature: string, valence: string, acoustic_vector_0: string, acoustic_vector_1: string, acoustic_vector_2: string, acoustic_vector_3: string, acoustic_vector_4: string, acoustic_vector_5: string, acoustic_vector_6: string, acoustic_vector_7: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- session_position: string (nullable = true)\n",
      " |-- session_length: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: string (nullable = true)\n",
      " |-- skip_2: string (nullable = true)\n",
      " |-- skip_3: string (nullable = true)\n",
      " |-- not_skipped: string (nullable = true)\n",
      " |-- context_switch: string (nullable = true)\n",
      " |-- no_pause_before_play: string (nullable = true)\n",
      " |-- short_pause_before_play: string (nullable = true)\n",
      " |-- long_pause_before_play: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekfwd: string (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: string (nullable = true)\n",
      " |-- hist_user_behavior_is_shuffle: string (nullable = true)\n",
      " |-- hour_of_day: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- premium: string (nullable = true)\n",
      " |-- context_type: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_start: string (nullable = true)\n",
      " |-- hist_user_behavior_reason_end: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spotify.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "|          session_id|      track_id_clean|skip_1|skip_2|skip_3|not_skipped|context_switch|no_pause_before_play|short_pause_before_play|long_pause_before_play|hist_user_behavior_n_seekback|premium|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...| false| false| false|       true|             0|                   0|                      0|                     0|                            0|   true|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+--------------------+-----------------------+----------------------+-----------------------------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\"hist_user_behavior_reason_start\", \"hist_user_behavior_reason_end\", \"context_type\", \"date\"\n",
    "                  ,\"hour_of_day\", \"hist_user_behavior_is_shuffle\", \"hist_user_behavior_n_seekfwd\", \"session_length\",\"session_position\"]\n",
    "df_drop = spotify.drop(*columns_to_drop)\n",
    "df_drop.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: boolean (nullable = true)\n",
      " |-- skip_2: boolean (nullable = true)\n",
      " |-- skip_3: boolean (nullable = true)\n",
      " |-- not_skipped: boolean (nullable = true)\n",
      " |-- context_switch: boolean (nullable = true)\n",
      " |-- no_pause_before_play: boolean (nullable = true)\n",
      " |-- short_pause_before_play: boolean (nullable = true)\n",
      " |-- long_pause_before_play: boolean (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: integer (nullable = true)\n",
      " |-- premium: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "for c in [\"skip_1\", \"skip_2\", \"skip_3\", \"not_skipped\", \"context_switch\", \"no_pause_before_play\",\n",
    "         \"short_pause_before_play\", \"long_pause_before_play\", \"premium\"]:\n",
    "    df_drop = df_drop.withColumn(c, df_drop[c].cast(BooleanType()))\n",
    "for c in [\"hist_user_behavior_n_seekback\"]:\n",
    "    df_drop = df_drop.withColumn(c, df_drop[c].cast(IntegerType()))  \n",
    "    \n",
    "df_drop.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------+------+-----------+--------------+-----------------------------+-------+---------+\n",
      "|          session_id|      track_id_clean|skip_1|skip_2|skip_3|not_skipped|context_switch|hist_user_behavior_n_seekback|premium|Not_Pause|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+-----------------------------+-------+---------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...| false| false| false|       true|         false|                            0|   true|        1|\n",
      "+--------------------+--------------------+------+------+------+-----------+--------------+-----------------------------+-------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- skip_1: boolean (nullable = true)\n",
      " |-- skip_2: boolean (nullable = true)\n",
      " |-- skip_3: boolean (nullable = true)\n",
      " |-- not_skipped: boolean (nullable = true)\n",
      " |-- context_switch: boolean (nullable = true)\n",
      " |-- hist_user_behavior_n_seekback: integer (nullable = true)\n",
      " |-- premium: boolean (nullable = true)\n",
      " |-- Not_Pause: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def pause_udf(short_pause, long_pause):\n",
    "    if short_pause or long_pause:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "pause = spark.udf.register(\"pause\", pause_udf)\n",
    "\n",
    "df1 = df_drop.select(\"session_id\", \"track_id_clean\", \"skip_1\", \"skip_2\", \"skip_3\",\n",
    "                     \"not_skipped\", \"context_switch\", \"hist_user_behavior_n_seekback\",\n",
    "                     \"premium\", pause(col(\"short_pause_before_play\"), col(\"long_pause_before_play\")).alias(\"Not_Pause\"))\n",
    "df1.show(1)\n",
    "\n",
    "#df_drop1 = df_drop.join(df1, [\"session_id\"] , \"left\")\n",
    "df1 = df1.withColumn(\"Not_Pause\", df1[\"Not_Pause\"].cast(IntegerType()))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+-----------------------------+-----------+\n",
      "|          session_id|context_switch|      track_id_clean|hist_user_behavior_n_seekback|Skip_Rating|\n",
      "+--------------------+--------------+--------------------+-----------------------------+-----------+\n",
      "|0_00006f66-33e5-4...|         false|t_0479f24c-27d2-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_9099cd7b-c238-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_fc5df5ba-5396-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_23cff8d6-d874-4...|                            0|          6|\n",
      "|0_00006f66-33e5-4...|         false|t_64f3743c-f624-4...|                            0|          6|\n",
      "+--------------------+--------------+--------------------+-----------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def skip_rating_udf(premium, skip_1, skip_2, skip_3, not_skip, nopause):\n",
    "    if premium:\n",
    "        if skip_1:\n",
    "            skip1 = 1 - (1 - nopause)\n",
    "        else:\n",
    "            skip1 = 0\n",
    "        if skip_2:\n",
    "            skip2 = 3\n",
    "        else:\n",
    "            skip2 = 0\n",
    "        if skip_3:\n",
    "            skip3 = 5\n",
    "        else:\n",
    "            skip3 = 0\n",
    "        if not_skip:\n",
    "            notskip = 6 + (2 - 2 * nopause)\n",
    "        else:\n",
    "            notskip = 0\n",
    "        return max(skip1, skip2, skip3, notskip)\n",
    "    else:\n",
    "        if skip_1:\n",
    "            skip1 = 0\n",
    "        else:\n",
    "            skip1 = 0\n",
    "        if skip_2:\n",
    "            skip2 = 1\n",
    "        else:\n",
    "            skip2 = 0\n",
    "        if skip_3:\n",
    "            skip3 = 2\n",
    "        else:\n",
    "            skip3 = 0\n",
    "        if not_skip:\n",
    "            notskip = 5 + (1 - 1 * nopause)\n",
    "        else:\n",
    "            notskip = 0\n",
    "        return max(skip1, skip2, skip3, notskip)\n",
    "    \n",
    "skip_rating = spark.udf.register(\"skip_rating\", skip_rating_udf)\n",
    "\n",
    "df2 = df1.select(\"session_id\",\"context_switch\",\"track_id_clean\",\n",
    "                 \"hist_user_behavior_n_seekback\",skip_rating(col(\"premium\"), col(\"skip_1\"), \n",
    "                                                             col(\"skip_2\"), col(\"skip_3\"), col(\"not_skipped\"), \n",
    "                                                             col(\"Not_Pause\")).alias(\"Skip_Rating\"))\n",
    "df2.show(5)\n",
    "\n",
    "#df_drop2 = df_drop1.join(df2, [\"session_id\"] , \"left\")\n",
    "df2 = df2.withColumn(\"Skip_Rating\", df2[\"Skip_Rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|          session_id|      track_id_clean|Final_Rating|\n",
      "+--------------------+--------------------+------------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_9099cd7b-c238-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_fc5df5ba-5396-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_23cff8d6-d874-4...|         6.0|\n",
      "|0_00006f66-33e5-4...|t_64f3743c-f624-4...|         6.0|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def final_rating_udf(Skip_Rating, context_switch, seekback):\n",
    "    if context_switch:\n",
    "        context = 1\n",
    "    else:\n",
    "        context = 0\n",
    "    inside = 1 - (Skip_Rating + 2*context)/10\n",
    "    seekback = seekback + 1\n",
    "    return (1 - pow(inside, (pow(seekback, 1/3)))) * 10\n",
    "\n",
    "final_rating = spark.udf.register(\"final_rating\", final_rating_udf)\n",
    "\n",
    "df3 = df2.select(\"session_id\", \"track_id_clean\",\n",
    "                 final_rating(col(\"Skip_Rating\"), col(\"context_switch\"),\n",
    "                              col(\"hist_user_behavior_n_seekback\")).alias(\"Final_Rating\"))\n",
    "df3.show(5)\n",
    "\n",
    "#df_drop3 = df_drop2.join(df3, [\"session_id\"] , \"left\")\n",
    "df3 = df3.withColumn(\"Final_Rating\", df3[\"Final_Rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|          session_id|      track_id_clean|Final_Rating_Adjust|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|0_00006f66-33e5-4...|t_0479f24c-27d2-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_9099cd7b-c238-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_fc5df5ba-5396-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_23cff8d6-d874-4...|                  7|\n",
      "|0_00006f66-33e5-4...|t_64f3743c-f624-4...|                  7|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def adjust_udf(final):\n",
    "    return final + 1\n",
    "\n",
    "adjust = spark.udf.register(\"adjust\", adjust_udf)\n",
    "\n",
    "df4 = df3.select(\"session_id\", \"track_id_clean\",\n",
    "                 adjust(col(\"Final_Rating\")).alias(\"Final_Rating_Adjust\"))\n",
    "df4.show(5)\n",
    "\n",
    "#df_drop3 = df_drop2.join(df3, [\"session_id\"] , \"left\")\n",
    "df4 = df4.withColumn(\"Final_Rating_Adjust\", df4[\"Final_Rating_Adjust\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4.write.format(\"csv\").option(\"header\",\"true\").mode(\"Overwrite\").save(\"s3://olihw4/spotify_full_version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|Final_Rating_Adjust|\n",
      "+-------+-------------------+\n",
      "|  count|         2072002577|\n",
      "|   mean|  5.916154485072342|\n",
      "| stddev| 1.7028280992338194|\n",
      "|    min|                  1|\n",
      "|    max|                 11|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.describe(\"Final_Rating_Adjust\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|Final_Rating_Adjust|count(session_id)|\n",
      "+-------------------+-----------------+\n",
      "|                  1|         32930593|\n",
      "|                  6|       1153802824|\n",
      "|                  3|          8332379|\n",
      "|                  5|          7127384|\n",
      "|                  9|         87913811|\n",
      "|                  4|           159804|\n",
      "|                  8|         46665799|\n",
      "|                  7|        510759745|\n",
      "|                 10|          1727159|\n",
      "|                 11|          4328875|\n",
      "|                  2|        218254204|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df4.groupBy(\"Final_Rating_Adjust\").agg(count('session_id')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- track_id_clean: string (nullable = true)\n",
      " |-- Final_Rating_Adjust: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part, _ = df4.randomSplit([0.04, 0.96])\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df_part) for column in [\"session_id\", \"track_id_clean\"] ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_index = pipeline.fit(df_part).transform(df_part)\n",
    "\n",
    "#df_index.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = df_index.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"session_id_index\", itemCol=\"track_id_clean_index\", ratingCol=\"Final_Rating_Adjust\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model, \"s3://olihw4//spotify_full_version_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 10.181823908017078\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Final_Rating_Adjust\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs.select(\"recommendations\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id_index: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- track_id_clean_index: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRecs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
